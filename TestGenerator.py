from openai import OpenAI
from dotenv import load_dotenv
import time
import argparse
from pathlib import Path
from typing import Tuple, Optional, List

def __init__() -> None:
    """
    Loads the .env file and initializes the OpenAi client. Additionally reads
    the System Prompt from the file stored in ./data/Prompts/SystemPrompt.txt
    and stores it in a global constant.
    """
    load_dotenv()
    global client
    client = OpenAI()
    with open('./data/Prompts/SystemPrompt.txt', 'r') as f:
        global SYSTEM_PROMPT
        SYSTEM_PROMPT = f.read()

def query_gpt(prompt: str, gpt_temperature: float = 0, gpt_model: str = 'gpt-4o-2024-05-13') -> str:
    """
    Sends the query to OpenAI's GPT completion API and returns the response.

    Arguments:
        prompt: Prompt used when querying GPT -> str
        gpt_temperature: Parameter used to determine the degree of randomness
                         in the LLM's output. In the range of [0, 1].
                         Default: 0
                         -> float
        gpt_model: The model to be used. Default 'gpt-4o-2024-05-13' -> str

    Return:
        The answer of the LLM as a string.
    """
    print('Querying GPT...')
    completion = client.chat.completions.create(
      model= gpt_model,
      response_format={ "type": "json_object" },
      temperature = gpt_temperature,
      messages=[
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": prompt}
      ]
    )
    return completion.choices[0].message.content

def get_prompt(program_name: str) -> Tuple[str, Optional[str]]:
    """
    Read the program specific prompt that is used to query the LLM from a text
    file. Tries also to find a second prompt to allow for more accurate results
    for long prompts.
    Returns a tuple of the two prompts. The second prompt will be None if no
    second file was found.

    Arguments:
        program_name: Name of the program for which to read the prompt -> str

    Return:
        Tuple of the prompts as strings. Second item can be None.
    """
    prompt = ''
    second_prompt = None
    path = Path(f'./data/Prompts/{program_name}_Prompt.txt')
    path2 = Path(f'./data/Prompts/{program_name}_Prompt2.txt')
    if path.exists():
        with open(path, 'r') as f:
            prompt = f.read()
    else:
        raise Exception(f'No prompt file for program name {program_name}')
    if path2.exists():
        with open(path2, 'r') as f:
            second_prompt = f.read()
    return prompt, second_prompt

def get_names() -> List[str]:
    """
    Reads all the program names from the file 'program_names.txt' and returns
    a list of all names.

    Return:
        List of all names.
    """
    names = []
    with open('program_names.txt', 'r') as f:
        names = f.readlines()
    for i in range(len(names)):
        names[i] = names[i].strip()
    return names

def write_JSON(program_name: str, generated: str) -> None:
    """
    Formats the recieved JSON into a human readable format and writes the result
    into a .json file at ./data/Tests/JSON.

    Arguments:
        program_name: Name of the program. Used for naming the resultign file -> str
        generated: The JSON generated by the LLM as a string -> str
    """
    generated = generated.replace('  ]\n}{\n  "tests": [', ',')
    generated = generated.replace('  ]\n}\n{\n  "tests": [', ',')
    with open(f'./data/Tests/JSON/{program_name}_Tests.json', 'w') as f:
        for line in generated:
            f.write(line)

def generate_tests(names: List[str]) -> None:
    """
    Generates the tests for all programs named in the input list by querying the
    LLM and writing the response into a .json file.

    Arguments:
        names: Names of the programs for which tests should be generated.
    """
    for program_name in names:
        print(f'Generating tests for {program_name}')
        prompt, second_prompt = get_prompt(program_name)
        response = query_gpt(prompt)
        if second_prompt != None:
            response = response + query_gpt(second_prompt)
        print('Writing response to files')
        write_JSON(program_name, response)
        print('Waiting for 10 seconds...')
        time.sleep(10)

def parse_command_line_inputs() -> Optional[List[str]]:
    """
    Parses the command line inputs and returns the specified names as a list.

    Return:
        A list of all specified names or None if no names were given as arguments.
    """
    parser = argparse.ArgumentParser(description='Querys the large language model for the programs specified')
    parser.add_argument('-n', '--names', action='extend', type=str, nargs='+', \
                        help='Names of the programs to test. If no names are given all names in program_names.txt are used instead')
    return parser.parse_args().names

def main() -> None:
    """
    Generates tests for the specified programs using OpenAI's GPT and stores the
    responses as JSON files.
    """
    names = parse_command_line_inputs()
    if names is None:
        names = get_names()
    generate_tests(names)


if __name__ == '__main__':
    __init__()
    main()
